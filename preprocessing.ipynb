{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pd\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import textblob, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/raw.csv\")\n",
    "df = df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title              author  \\\n",
       "id                                                                          \n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2                   Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                 text  \n",
       "id                                                     \n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "1   Ever get the feeling your life circles the rou...  \n",
       "2   Why the Truth Might Get You Fired October 29, ...  \n",
       "3   Videos 15 Civilians Killed In Single US Airstr...  \n",
       "4   Print \\nAn Iranian woman has been sentenced to...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the Independent Features\n",
    "X = df.drop(\"label\",axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the Dependent features\n",
    "y = df[\"label\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop null values\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "82                                                        \n",
       "169                                                       \n",
       "173                                        Guest   Guest  \n",
       "295                                                       \n",
       "470                                                       \n",
       "                               ...                        \n",
       "20264                                                     \n",
       "20348    \\n\\nMindblowing Reason Elites Fear Donald Trum...\n",
       "20418                                      Guest   Guest  \n",
       "20431         \\nOctober 28, 2016 The Mothers by stclair by\n",
       "20513                                                     \n",
       "Name: text, Length: 107, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a variable called length for the length of the text\n",
    "length = []\n",
    "[length.append(len(str(text))) for text in df['text']]\n",
    "df['length'] = length\n",
    "df.head()\n",
    "\n",
    "#dropping length less than 50\n",
    "df['text'][df['length'] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Benoît Hamon Wins French Socialist Party’s Presidential Nomination - The New York Times'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=df.copy()\n",
    "messages.reset_index(inplace=True)\n",
    "messages.head(10)\n",
    "messages['title'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", messages[\"title\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words(\"english\")]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words with ngram for more meaning from the document\n",
    "cv = CountVectorizer(max_features=5000,ngram_range=(1,3))\n",
    "X_bow = cv.fit_transform(corpus).toarray()\n",
    "X_bow.shape\n",
    "y = messages[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abc',\n",
       " 'abc news',\n",
       " 'abduct',\n",
       " 'abe',\n",
       " 'abedin',\n",
       " 'abl',\n",
       " 'abort',\n",
       " 'abroad',\n",
       " 'absolut',\n",
       " 'abstain',\n",
       " 'absurd',\n",
       " 'abus',\n",
       " 'abus new',\n",
       " 'abus new york',\n",
       " 'academi',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'access pipelin',\n",
       " 'access pipelin protest']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Divide the dataset into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, y, test_size=0.25, random_state=0)\n",
    "cv.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abl</th>\n",
       "      <th>abort</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolut</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zika viru</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone new</th>\n",
       "      <th>zone new york</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abc  abc news  abduct  abe  abedin  abl  abort  abroad  absolut  \\\n",
       "0        0    0         0       0    0       0    0      0       0        0   \n",
       "1        0    0         0       0    0       0    0      0       0        0   \n",
       "2        0    0         0       0    0       0    0      0       0        0   \n",
       "3        0    0         0       0    0       1    0      0       0        0   \n",
       "4        0    0         0       0    0       0    0      0       0        0   \n",
       "\n",
       "   ...  zero  zika  zika viru  zionist  zone  zone new  zone new york  zoo  \\\n",
       "0  ...     0     0          0        0     0         0              0    0   \n",
       "1  ...     0     0          0        0     0         0              0    0   \n",
       "2  ...     0     0          0        0     0         0              0    0   \n",
       "3  ...     0     0          0        0     0         0              0    0   \n",
       "4  ...     0     0          0        0     0         0              0    0   \n",
       "\n",
       "   zu  zuckerberg  \n",
       "0   0           0  \n",
       "1   0           0  \n",
       "2   0           0  \n",
       "3   0           0  \n",
       "4   0           0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## gives you the various parameters of count vectorizers\n",
    "cv.get_params()\n",
    "train_bow_df = pd.DataFrame(X_train_bow, columns=cv.get_feature_names())\n",
    "train_bow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abl</th>\n",
       "      <th>abort</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolut</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zika viru</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone new</th>\n",
       "      <th>zone new york</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abc  abc news  abduct  abe  abedin  abl  abort  abroad  absolut  \\\n",
       "0        0    0         0       0    0       0    0      0       0        0   \n",
       "1        0    0         0       0    0       0    0      0       0        0   \n",
       "2        0    0         0       0    0       0    0      0       0        0   \n",
       "3        0    0         0       0    0       0    0      0       0        0   \n",
       "4        0    0         0       0    0       0    0      0       0        0   \n",
       "\n",
       "   ...  zero  zika  zika viru  zionist  zone  zone new  zone new york  zoo  \\\n",
       "0  ...     0     0          0        0     0         0              0    0   \n",
       "1  ...     0     0          0        0     0         0              0    0   \n",
       "2  ...     0     0          0        0     0         0              0    0   \n",
       "3  ...     0     0          0        0     0         0              0    0   \n",
       "4  ...     0     0          0        0     0         0              0    0   \n",
       "\n",
       "   zu  zuckerberg  \n",
       "0   0           0  \n",
       "1   0           0  \n",
       "2   0           0  \n",
       "3   0           0  \n",
       "4   0           0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bow_df = pd.DataFrame(X_test_bow, columns=cv.get_feature_names())\n",
    "test_bow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using TFIDF which down weights unimportant words that appear with high frequency\n",
    "tfidf_v = TfidfVectorizer(max_features=5000,ngram_range=(1,3))\n",
    "X_tfid = tfidf_v.fit_transform(corpus).toarray()\n",
    "y = messages[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abc',\n",
       " 'abc news',\n",
       " 'abduct',\n",
       " 'abe',\n",
       " 'abedin',\n",
       " 'abl',\n",
       " 'abort',\n",
       " 'abroad',\n",
       " 'absolut',\n",
       " 'abstain',\n",
       " 'absurd',\n",
       " 'abus',\n",
       " 'abus new',\n",
       " 'abus new york',\n",
       " 'academi',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'access pipelin',\n",
       " 'access pipelin protest']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting\n",
    "X_train_tfid, X_test_tfid, y_train_tfid, y_test_tfid = train_test_split(X_tfid, y, test_size=0.25, random_state=0)\n",
    "tfidf_v.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abl</th>\n",
       "      <th>abort</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolut</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zika viru</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone new</th>\n",
       "      <th>zone new york</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abc  abc news  abduct  abe   abedin  abl  abort  abroad  absolut  \\\n",
       "0      0.0  0.0       0.0     0.0  0.0  0.00000  0.0    0.0     0.0      0.0   \n",
       "1      0.0  0.0       0.0     0.0  0.0  0.00000  0.0    0.0     0.0      0.0   \n",
       "2      0.0  0.0       0.0     0.0  0.0  0.00000  0.0    0.0     0.0      0.0   \n",
       "3      0.0  0.0       0.0     0.0  0.0  0.31335  0.0    0.0     0.0      0.0   \n",
       "4      0.0  0.0       0.0     0.0  0.0  0.00000  0.0    0.0     0.0      0.0   \n",
       "\n",
       "   ...  zero  zika  zika viru  zionist  zone  zone new  zone new york  zoo  \\\n",
       "0  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "1  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "2  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "3  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "4  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "\n",
       "    zu  zuckerberg  \n",
       "0  0.0         0.0  \n",
       "1  0.0         0.0  \n",
       "2  0.0         0.0  \n",
       "3  0.0         0.0  \n",
       "4  0.0         0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualise\n",
    "train_tfidf_df = pd.DataFrame(X_train_tfid, columns=cv.get_feature_names())\n",
    "train_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abl</th>\n",
       "      <th>abort</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolut</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zika viru</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone new</th>\n",
       "      <th>zone new york</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abc  abc news  abduct  abe  abedin  abl  abort  abroad  absolut  \\\n",
       "0      0.0  0.0       0.0     0.0  0.0     0.0  0.0    0.0     0.0      0.0   \n",
       "1      0.0  0.0       0.0     0.0  0.0     0.0  0.0    0.0     0.0      0.0   \n",
       "2      0.0  0.0       0.0     0.0  0.0     0.0  0.0    0.0     0.0      0.0   \n",
       "3      0.0  0.0       0.0     0.0  0.0     0.0  0.0    0.0     0.0      0.0   \n",
       "4      0.0  0.0       0.0     0.0  0.0     0.0  0.0    0.0     0.0      0.0   \n",
       "\n",
       "   ...  zero  zika  zika viru  zionist  zone  zone new  zone new york  zoo  \\\n",
       "0  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "1  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "2  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "3  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "4  ...   0.0   0.0        0.0      0.0   0.0       0.0            0.0  0.0   \n",
       "\n",
       "    zu  zuckerberg  \n",
       "0  0.0         0.0  \n",
       "1  0.0         0.0  \n",
       "2  0.0         0.0  \n",
       "3  0.0         0.0  \n",
       "4  0.0         0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualise\n",
    "test_tfidf_df = pd.DataFrame(X_test_tfid, columns=cv.get_feature_names())\n",
    "test_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embeddings are an improvement over more the traditional bag-of-word model encoding schemes where large sparse vectors were used to represent each word or to score each word within a vector to represent an entire vocabulary. These representations were sparse because the vocabularies were vast and a given word or document would be represented by a large vector comprised mostly of zero values.\n",
    "#instead, in an embedding, words are represented by dense vectors where a vector represents the projection of the word into a continuous vector space.\n",
    "#better fit for cnn otherwise input would be a 1x5000 matrix for bow\n",
    "#this splits data into positive and negative, train and test files to be used in word embeddings later\n",
    "df[\"data\"] = 'title: ' + df['title'].astype(str) \\\n",
    "        + ' author: ' + df['author'].astype(str) \\\n",
    "        + ' text: ' + df['text'].astype(str) \n",
    "positive_examples = df.query('label==1').drop(['title', 'author', 'text', 'label'], axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "positive_examples_train, positive_examples_test = train_test_split(positive_examples, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_examples = df.query('label==0').drop(['title', 'author', 'text', 'label'], axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "negative_examples_train, negative_examples_test = train_test_split(negative_examples, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, positive_examples_small = train_test_split(positive_examples_test, test_size=0.05)\n",
    "_, negative_examples_small = train_test_split(negative_examples_test, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_bow = y_train_bow.reset_index().drop(\"index\", axis = 1)\n",
    "train_bow_df[\"isFakeNews\"] = y_train_bow\n",
    "train_bow_df.to_csv(\"./data/train_bow.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tfid = y_train_tfid.reset_index().drop(\"index\", axis = 1)\n",
    "train_tfidf_df[\"isFakeNews\"] = y_train_tfid\n",
    "train_tfidf_df.to_csv(\"./data/train_tfidf.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bow = y_test_bow.reset_index().drop(\"index\", axis = 1)\n",
    "test_bow_df[\"isFakeNews\"] = y_test_bow\n",
    "test_bow_df.to_csv(\"./data/test_bow.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples.to_csv(\"./data/positive_examples.csv\", index = False)\n",
    "negative_examples.to_csv(\"./data/negative_examples.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_df.to_csv(\"./data/negative_examples.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tfid = y_test_tfid.reset_index().drop(\"index\", axis = 1)\n",
    "test_tfidf_df[\"isFakeNews\"] = y_test_tfid\n",
    "test_tfidf_df.to_csv(\"./data/test_tfidf.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples_train.to_csv(\"./data/positive_examples_train.txt\", sep=',', encoding='utf-8', header=None, index=False)\n",
    "positive_examples_test.to_csv(\"./data/positive_examples_test.txt\", sep=',', encoding='utf-8', header=None, index=False)\n",
    "negative_examples_train.to_csv(\"./data/negative_examples_train.txt\", sep=',', encoding='utf-8', header=None, index=False)\n",
    "negative_examples_test.to_csv(\"./data/negative_examples_test.txt\", sep=',', encoding='utf-8', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples_small.to_csv(\"./data/positive_examples_small.txt\", sep=',', encoding='utf-8', header=None, index=False)\n",
    "negative_examples_small.to_csv(\"./data/negative_examples_small.txt\", sep=',', encoding='utf-8', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for the modelling: we have 2 sets of training and validation data, 1 is count and the other is tfid, use the respective X and Y train/valid data sets.\n",
    "\n",
    "I have chosen a 75/25 train test split according the size of the data and googling online. Change it if you find something more suitable.\n",
    "\n",
    "Preprocessing summary: removed null values, removed blank/short meaningless text. Removed stop words and non-english characters. We end up with 2 set of vectors that we can work with."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}